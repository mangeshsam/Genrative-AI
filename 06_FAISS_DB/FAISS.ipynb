{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7bdd2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_text = \"\"\" \n",
    "Mangesh Sambare is an Indian Junior Data Scientist, AI Trainer, Technical Mentor, and Startup Professional with strong hands-on experience in Machine Learning, Deep Learning, Natural Language Processing, Data Analytics, and Generative AI. He is professionally associated with Affordable AI Technology, a data science and AI-focused organization that provides live project-based training, internships, and real-world industry exposure to students and freshers. He actively contributes to both technical development and training delivery within the organization.\n",
    "\n",
    "His primary technical expertise lies in Python and SQL for data analysis, preprocessing, automation, and backend logic. He works extensively with machine learning and deep learning frameworks such as TensorFlow and scikit-learn, and has experience building models using CNNs, LSTMs, RNNs, and traditional supervised and unsupervised learning algorithms. His workflow typically includes data collection, cleaning, feature engineering, model training, evaluation, optimization, and deployment.\n",
    "\n",
    "At Affordable AI Technology, Mangesh Sambare works as a Junior Data Scientist and Project Mentor, where he leads and supports multiple client-based and internal AI projects. His work includes NLP-based systems, time series forecasting models, AI chatbots, data dashboards, and automation pipelines. He plays a key role in mentoring interns and trainees by guiding them through Python programming, SQL querying, machine learning concepts, deployment practices, and real-time project execution. He is directly involved in delivering internship programs that emphasize hands-on learning with live datasets and industry-style problem statements. The organization operates with a strong focus on practical skills, real client exposure, and career-oriented training, and its branch operations have expanded to locations such as Buttibori.\n",
    "\n",
    "Before this role, he worked as a Data Analytics Intern at Softronix Software Services Pvt. Ltd., where he gained industry experience in data extraction, automation, and reporting. During this internship, he automated large-scale e-commerce data scraping using Selenium, BeautifulSoup, and ChromeDriver, significantly reducing manual data collection effort. He also designed a Flask-based data pipeline to handle automated data ingestion, preprocessing, and analysis. In addition, he developed Excel-based dashboards and reports to track business KPIs and product performance.\n",
    "\n",
    "Mangesh Sambare has completed several end-to-end machine learning and deep learning projects. He developed a fashion item classification system using Convolutional Neural Networks trained on the Fashion MNIST dataset, achieving approximately ninety-two percent accuracy through proper normalization, dropout regularization, and activation tuning. He built an LSTM-based sentiment analysis system for e-commerce reviews using thousands of labeled samples and achieved over ninety-two percent accuracy. This system was integrated into a Flask web application for real-time sentiment prediction. He also completed a Flipkart product feedback analysis project involving the scraping of more than five thousand product reviews and ratings, followed by sentiment analysis and insight generation. Additionally, he developed automated image dataset acquisition tools using web scraping to collect high-quality image datasets from dynamically loaded web pages.\n",
    "\n",
    "His technical skill set spans Python, SQL, Pandas, NumPy, Machine Learning, Deep Learning, NLP, Computer Vision, Time Series Forecasting, Feature Engineering, Model Evaluation, Hyperparameter Tuning, ETL pipelines, Data Warehousing concepts, RESTful APIs, Flask-based backend systems, Power BI dashboards, Excel analytics, web scraping, automation, Git, GitHub, and Agile-style project workflows. He is comfortable working on both research-oriented prototypes and production-style applications.\n",
    "\n",
    "Apart from development work, Mangesh Sambare is deeply involved in teaching, mentoring, and content creation. He conducts structured training programs in Python, Data Science, Machine Learning, NLP, Deep Learning, Generative AI, Power BI, and Advanced Excel. His teaching approach emphasizes real-world examples, interview-oriented problem solving, and hands-on live projects. He regularly designs short-term courses such as Python Basics programs, Machine Learning bootcamps, and Data Science internship tracks that include training, project work, and career guidance.\n",
    "\n",
    "He runs a technical YouTube channel named “LearnCode_Mangesh” (also known as “LearnCode Infinity by Mangesh Sambare”), where he publishes educational videos on Python programming, data science fundamentals, machine learning algorithms, SQL roadmaps, interview preparation, coding logic, and real-time project demonstrations. His content targets beginners, students, interns, and early-career professionals aiming to enter the data science and AI field.\n",
    "\n",
    "Mangesh Sambare maintains an active GitHub profile where he hosts machine learning, NLP, generative AI, RAG-based systems, web scraping projects, and deployment-ready applications. His repositories often include complete pipelines, documentation, and practical implementations. On LinkedIn, he shares professional updates, technical milestones, training initiatives, and project-related insights, engaging with the broader data science and AI community.\n",
    "\n",
    "He holds a Master of Science degree in Electronics from RTMNU Campus, Maharashtra, completed between 2020 and 2022, and a Bachelor of Science degree in Physics, Mathematics, and Electronics from Kamla Nehru College, Nagpur, completed between 2016 and 2020. He has completed a Data Science Bootcamp from iNeuron and holds a Power BI certification from Satish Dhawale.\n",
    "\n",
    "Overall, Mangesh Sambare’s professional profile represents a combination of applied data science, AI engineering, technical mentoring, startup involvement, and educational content creation. His work focuses on building practical, scalable, and industry-relevant AI solutions while simultaneously training and guiding students and interns to become job-ready data professionals.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7b6078ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9545dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text,chunk_size = 400,overlap=40):\n",
    "    words = text.split()\n",
    "    chunks=  []\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = min(start + chunk_size,len(words))\n",
    "        chunk = ' '.join(words[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start +=chunk_size - overlap\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "344706be",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_text(bio_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5fb3c2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mangesh Sambare is an Indian Junior Data Scientist, AI Trainer, Technical Mentor, and Startup Professional with strong hands-on experience in Machine Learning, Deep Learning, Natural Language Processing, Data Analytics, and Generative AI. He is professionally associated with Affordable AI Technology, a data science and AI-focused organization that provides live project-based training, internships, and real-world industry exposure to students and freshers. He actively contributes to both technical development and training delivery within the organization. His primary technical expertise lies in Python and SQL for data analysis, preprocessing, automation, and backend logic. He works extensively with machine learning and deep learning frameworks such as TensorFlow and scikit-learn, and has experience building models using CNNs, LSTMs, RNNs, and traditional supervised and unsupervised learning algorithms. His workflow typically includes data collection, cleaning, feature engineering, model training, evaluation, optimization, and deployment. At Affordable AI Technology, Mangesh Sambare works as a Junior Data Scientist and Project Mentor, where he leads and supports multiple client-based and internal AI projects. His work includes NLP-based systems, time series forecasting models, AI chatbots, data dashboards, and automation pipelines. He plays a key role in mentoring interns and trainees by guiding them through Python programming, SQL querying, machine learning concepts, deployment practices, and real-time project execution. He is directly involved in delivering internship programs that emphasize hands-on learning with live datasets and industry-style problem statements. The organization operates with a strong focus on practical skills, real client exposure, and career-oriented training, and its branch operations have expanded to locations such as Buttibori. Before this role, he worked as a Data Analytics Intern at Softronix Software Services Pvt. Ltd., where he gained industry experience in data extraction, automation, and reporting. During this internship, he automated large-scale e-commerce data scraping using Selenium, BeautifulSoup, and ChromeDriver, significantly reducing manual data collection effort. He also designed a Flask-based data pipeline to handle automated data ingestion, preprocessing, and analysis. In addition, he developed Excel-based dashboards and reports to track business KPIs and product performance. Mangesh Sambare has completed several end-to-end machine learning and deep learning projects. He developed a fashion item classification system using Convolutional Neural Networks trained on the Fashion MNIST dataset, achieving approximately ninety-two percent accuracy through proper normalization, dropout regularization, and activation tuning. He built an LSTM-based sentiment analysis system for e-commerce reviews using thousands of labeled samples and achieved over ninety-two percent accuracy. This system was integrated into a Flask web application',\n",
       " 'percent accuracy through proper normalization, dropout regularization, and activation tuning. He built an LSTM-based sentiment analysis system for e-commerce reviews using thousands of labeled samples and achieved over ninety-two percent accuracy. This system was integrated into a Flask web application for real-time sentiment prediction. He also completed a Flipkart product feedback analysis project involving the scraping of more than five thousand product reviews and ratings, followed by sentiment analysis and insight generation. Additionally, he developed automated image dataset acquisition tools using web scraping to collect high-quality image datasets from dynamically loaded web pages. His technical skill set spans Python, SQL, Pandas, NumPy, Machine Learning, Deep Learning, NLP, Computer Vision, Time Series Forecasting, Feature Engineering, Model Evaluation, Hyperparameter Tuning, ETL pipelines, Data Warehousing concepts, RESTful APIs, Flask-based backend systems, Power BI dashboards, Excel analytics, web scraping, automation, Git, GitHub, and Agile-style project workflows. He is comfortable working on both research-oriented prototypes and production-style applications. Apart from development work, Mangesh Sambare is deeply involved in teaching, mentoring, and content creation. He conducts structured training programs in Python, Data Science, Machine Learning, NLP, Deep Learning, Generative AI, Power BI, and Advanced Excel. His teaching approach emphasizes real-world examples, interview-oriented problem solving, and hands-on live projects. He regularly designs short-term courses such as Python Basics programs, Machine Learning bootcamps, and Data Science internship tracks that include training, project work, and career guidance. He runs a technical YouTube channel named “LearnCode_Mangesh” (also known as “LearnCode Infinity by Mangesh Sambare”), where he publishes educational videos on Python programming, data science fundamentals, machine learning algorithms, SQL roadmaps, interview preparation, coding logic, and real-time project demonstrations. His content targets beginners, students, interns, and early-career professionals aiming to enter the data science and AI field. Mangesh Sambare maintains an active GitHub profile where he hosts machine learning, NLP, generative AI, RAG-based systems, web scraping projects, and deployment-ready applications. His repositories often include complete pipelines, documentation, and practical implementations. On LinkedIn, he shares professional updates, technical milestones, training initiatives, and project-related insights, engaging with the broader data science and AI community. He holds a Master of Science degree in Electronics from RTMNU Campus, Maharashtra, completed between 2020 and 2022, and a Bachelor of Science degree in Physics, Mathematics, and Electronics from Kamla Nehru College, Nagpur, completed between 2016 and 2020. He has completed a Data Science Bootcamp from iNeuron and holds a Power BI certification from Satish Dhawale. Overall, Mangesh',\n",
       " 'a Bachelor of Science degree in Physics, Mathematics, and Electronics from Kamla Nehru College, Nagpur, completed between 2016 and 2020. He has completed a Data Science Bootcamp from iNeuron and holds a Power BI certification from Satish Dhawale. Overall, Mangesh Sambare’s professional profile represents a combination of applied data science, AI engineering, technical mentoring, startup involvement, and educational content creation. His work focuses on building practical, scalable, and industry-relevant AI solutions while simultaneously training and guiding students and interns to become job-ready data professionals.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28e44fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6143"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bio_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "693d316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URI = \"https://api.euron.one/api/v1/euri/embeddings\"\n",
    "API_KEY = \"euri-6c93f5f50ee246146f624f32ba61c7fdaeed00fd4d6f7f8b8c7730b9dad3d231\"\n",
    "MODEL_NAME = \"text-embedding-3-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f25ab832",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\n",
    "    \"Content-Type\":\"application/json\",\n",
    "    \"Authorization\":f\"Bearer {API_KEY}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "73e98fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embedding = []\n",
    "for i,chunk in enumerate(chunks):\n",
    "    payload={\n",
    "        \"model\":MODEL_NAME,\n",
    "        \"input\":chunk\n",
    "    }\n",
    "    responce = requests.post(API_URI,headers=header,data = json.dumps(payload))\n",
    "    result  = responce.json()\n",
    "    embedding = result[\"data\"][0][\"embedding\"]\n",
    "    all_embedding.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1c964c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 'list',\n",
       " 'data': [{'object': 'embedding',\n",
       "   'embedding': [0.023845285,\n",
       "    -0.018081943,\n",
       "    0.020523664,\n",
       "    0.028266784,\n",
       "    0.020083714,\n",
       "    -0.026638968,\n",
       "    0.020886622,\n",
       "    0.04260915,\n",
       "    0.0036955795,\n",
       "    -0.024835173,\n",
       "    0.033502188,\n",
       "    0.0027991815,\n",
       "    -0.07492347,\n",
       "    -0.016058173,\n",
       "    0.020171704,\n",
       "    0.089309834,\n",
       "    -0.008645016,\n",
       "    0.007616633,\n",
       "    -0.0061043054,\n",
       "    0.018037947,\n",
       "    0.033348203,\n",
       "    0.012846538,\n",
       "    0.064628646,\n",
       "    -0.0100583555,\n",
       "    0.030862488,\n",
       "    -0.0036680824,\n",
       "    0.032006357,\n",
       "    0.024527209,\n",
       "    0.014947299,\n",
       "    0.01994073,\n",
       "    0.02265742,\n",
       "    -0.013253491,\n",
       "    -0.013781431,\n",
       "    0.0015164524,\n",
       "    0.006621246,\n",
       "    0.016564114,\n",
       "    -0.016564114,\n",
       "    0.008155572,\n",
       "    -0.009788886,\n",
       "    -0.009079467,\n",
       "    -0.0057963403,\n",
       "    -0.055037737,\n",
       "    -0.0005819025,\n",
       "    0.08631817,\n",
       "    -0.00054512545,\n",
       "    -0.018862853,\n",
       "    -0.04252116,\n",
       "    -0.02479118,\n",
       "    0.020688646,\n",
       "    0.03875959,\n",
       "    -0.011218723,\n",
       "    -0.0289927,\n",
       "    0.016971068,\n",
       "    0.015585226,\n",
       "    -0.022426447,\n",
       "    0.009629404,\n",
       "    0.02152455,\n",
       "    0.0058898297,\n",
       "    -0.008331552,\n",
       "    -0.03306224,\n",
       "    0.017861968,\n",
       "    -0.0108007705,\n",
       "    0.0014435857,\n",
       "    0.037857693,\n",
       "    0.019753752,\n",
       "    0.04584278,\n",
       "    -0.029850602,\n",
       "    0.015475239,\n",
       "    0.0022643672,\n",
       "    -0.0137154395,\n",
       "    0.030708505,\n",
       "    0.049362384,\n",
       "    -0.028420765,\n",
       "    0.013341482,\n",
       "    -0.002793682,\n",
       "    -0.0138804205,\n",
       "    0.021073602,\n",
       "    -0.0048366995,\n",
       "    0.017773977,\n",
       "    -0.025847059,\n",
       "    0.0057963403,\n",
       "    0.02679295,\n",
       "    0.04357704,\n",
       "    -0.023713302,\n",
       "    -0.050286278,\n",
       "    0.030598518,\n",
       "    0.006263787,\n",
       "    -0.0029339162,\n",
       "    -0.0694241,\n",
       "    0.012329597,\n",
       "    -0.01994073,\n",
       "    -0.06955609,\n",
       "    -0.047118638,\n",
       "    0.0064452663,\n",
       "    0.031830378,\n",
       "    0.0058183377,\n",
       "    0.073471636,\n",
       "    -0.04267514,\n",
       "    0.037549727,\n",
       "    0.030202562,\n",
       "    -0.048306502,\n",
       "    0.027760841,\n",
       "    0.017576,\n",
       "    0.01694907,\n",
       "    0.051166177,\n",
       "    -0.0042510163,\n",
       "    0.010756776,\n",
       "    -0.05763344,\n",
       "    0.027056921,\n",
       "    0.00799059,\n",
       "    -0.0711839,\n",
       "    0.0016333141,\n",
       "    0.026067033,\n",
       "    0.008738506,\n",
       "    -0.042565156,\n",
       "    -0.034822036,\n",
       "    0.028684735,\n",
       "    -0.024967158,\n",
       "    -0.04821851,\n",
       "    0.0070007034,\n",
       "    0.0070007034,\n",
       "    0.05684153,\n",
       "    0.005067673,\n",
       "    -0.056049623,\n",
       "    -0.0030961477,\n",
       "    -0.004894443,\n",
       "    0.013275489,\n",
       "    -0.026682964,\n",
       "    0.022030493,\n",
       "    -0.016454127,\n",
       "    -0.018213928,\n",
       "    -0.047822557,\n",
       "    0.06159299,\n",
       "    -0.03260029,\n",
       "    0.022184474,\n",
       "    -0.038253646,\n",
       "    -0.040497392,\n",
       "    -0.024901167,\n",
       "    -0.03486603,\n",
       "    -0.013011519,\n",
       "    -0.012846538,\n",
       "    0.0281128,\n",
       "    0.007979591,\n",
       "    -0.016828084,\n",
       "    -0.035657942,\n",
       "    -0.00896398,\n",
       "    0.025055148,\n",
       "    0.021381566,\n",
       "    0.022987384,\n",
       "    -0.015959183,\n",
       "    -0.020369682,\n",
       "    0.037571725,\n",
       "    -0.008254561,\n",
       "    -0.010399316,\n",
       "    0.026023038,\n",
       "    0.009046471,\n",
       "    0.019819744,\n",
       "    -0.00022014682,\n",
       "    -0.021073602,\n",
       "    -0.025319118,\n",
       "    0.012329597,\n",
       "    0.01915982,\n",
       "    -0.033150226,\n",
       "    0.024615198,\n",
       "    0.023295349,\n",
       "    -0.0042620148,\n",
       "    -0.032314323,\n",
       "    -0.0068412214,\n",
       "    -0.039155543,\n",
       "    -0.048790447,\n",
       "    -0.03504201,\n",
       "    -0.020842629,\n",
       "    0.007655129,\n",
       "    -0.043467052,\n",
       "    0.039595492,\n",
       "    0.05323394,\n",
       "    0.006131802,\n",
       "    -0.0020608904,\n",
       "    -0.04865846,\n",
       "    -0.07677126,\n",
       "    -0.037659712,\n",
       "    0.007985091,\n",
       "    -0.004058538,\n",
       "    0.026858943,\n",
       "    -0.028420765,\n",
       "    0.022591429,\n",
       "    0.03724176,\n",
       "    0.028156795,\n",
       "    0.006472763,\n",
       "    0.0202157,\n",
       "    0.019929731,\n",
       "    0.040453397,\n",
       "    -0.027276896,\n",
       "    0.03110446,\n",
       "    -0.002170878,\n",
       "    -0.050814215,\n",
       "    0.01414439,\n",
       "    -0.02793682,\n",
       "    -0.04293911,\n",
       "    -0.04456693,\n",
       "    0.015596225,\n",
       "    -0.020094713,\n",
       "    0.043357067,\n",
       "    0.037747703,\n",
       "    0.012549572,\n",
       "    -0.017971955,\n",
       "    0.055653665,\n",
       "    -0.029388655,\n",
       "    -0.018763864,\n",
       "    -0.023999268,\n",
       "    0.038341638,\n",
       "    0.014738322,\n",
       "    0.054861758,\n",
       "    0.01994073,\n",
       "    -0.056621555,\n",
       "    -0.014177387,\n",
       "    -0.035393972,\n",
       "    -0.009761389,\n",
       "    0.013913416,\n",
       "    -0.0031208948,\n",
       "    0.0068907156,\n",
       "    0.045094866,\n",
       "    -0.0063572763,\n",
       "    -0.002601204,\n",
       "    0.0007582262,\n",
       "    -0.009381932,\n",
       "    0.02205249,\n",
       "    -0.017641991,\n",
       "    0.06251688,\n",
       "    -0.049978312,\n",
       "    0.0012923529,\n",
       "    0.0061537996,\n",
       "    0.011031744,\n",
       "    0.0465467,\n",
       "    -0.012538573,\n",
       "    0.022833401,\n",
       "    0.04067337,\n",
       "    0.021249581,\n",
       "    -0.03145642,\n",
       "    0.014683329,\n",
       "    -0.027606858,\n",
       "    0.032204334,\n",
       "    0.043005105,\n",
       "    0.009618405,\n",
       "    0.012439584,\n",
       "    0.006670741,\n",
       "    -0.00087577535,\n",
       "    -0.015706213,\n",
       "    -0.034910027,\n",
       "    0.00782011,\n",
       "    0.0030823993,\n",
       "    0.011471694,\n",
       "    0.0094204275,\n",
       "    -0.046502706,\n",
       "    -0.042543158,\n",
       "    -0.048394494,\n",
       "    -0.02214048,\n",
       "    0.031676393,\n",
       "    0.02143656,\n",
       "    0.001642938,\n",
       "    -0.0050374265,\n",
       "    0.002906419,\n",
       "    -0.022008495,\n",
       "    -0.022470443,\n",
       "    -0.034844033,\n",
       "    0.025165135,\n",
       "    -0.02188751,\n",
       "    -0.020798633,\n",
       "    -0.014441356,\n",
       "    -0.02170053,\n",
       "    -0.0068247234,\n",
       "    -0.004457243,\n",
       "    -0.0074021574,\n",
       "    0.02144756,\n",
       "    -0.0071766833,\n",
       "    0.011548686,\n",
       "    0.0017446764,\n",
       "    0.024879169,\n",
       "    -0.013165502,\n",
       "    0.00030504342,\n",
       "    -0.008744005,\n",
       "    0.032446306,\n",
       "    0.009865877,\n",
       "    0.03277627,\n",
       "    -0.015882192,\n",
       "    0.017740982,\n",
       "    0.024725186,\n",
       "    0.028486758,\n",
       "    -0.021425562,\n",
       "    -0.07008402,\n",
       "    0.029564636,\n",
       "    0.0016181908,\n",
       "    -0.006835722,\n",
       "    0.008568025,\n",
       "    0.06361676,\n",
       "    -0.06810425,\n",
       "    0.0033821152,\n",
       "    0.0059943176,\n",
       "    0.0005310333,\n",
       "    0.014276375,\n",
       "    -0.026287008,\n",
       "    -0.0049081915,\n",
       "    0.026462989,\n",
       "    -0.008463536,\n",
       "    -0.0024760931,\n",
       "    -0.004369253,\n",
       "    0.021832515,\n",
       "    0.03488803,\n",
       "    0.04183924,\n",
       "    -0.021370567,\n",
       "    -0.0090079745,\n",
       "    -0.011581682,\n",
       "    -0.0138804205,\n",
       "    -0.013836425,\n",
       "    -0.041421287,\n",
       "    -0.03306224,\n",
       "    0.0112847155,\n",
       "    -0.043950997,\n",
       "    0.003558095,\n",
       "    -0.01326449,\n",
       "    0.021755524,\n",
       "    -0.032116346,\n",
       "    0.019610768,\n",
       "    -0.054113843,\n",
       "    -0.016267149,\n",
       "    0.019995725,\n",
       "    -0.014826313,\n",
       "    0.011647674,\n",
       "    -0.0008111577,\n",
       "    0.0038963065,\n",
       "    0.0154972365,\n",
       "    0.0035250988,\n",
       "    -0.011015247,\n",
       "    -0.008133574,\n",
       "    0.0051006693,\n",
       "    0.06300083,\n",
       "    0.004778956,\n",
       "    0.0058458345,\n",
       "    0.0028459262,\n",
       "    -0.001370719,\n",
       "    -0.043687027,\n",
       "    -0.06493661,\n",
       "    -0.041597266,\n",
       "    -0.009304941,\n",
       "    0.041047327,\n",
       "    -0.0015013291,\n",
       "    -0.04848248,\n",
       "    0.0738236,\n",
       "    0.0030686508,\n",
       "    -0.0066927383,\n",
       "    -0.014595339,\n",
       "    -0.022899393,\n",
       "    0.045754794,\n",
       "    0.008199567,\n",
       "    0.018521892,\n",
       "    -0.03207235,\n",
       "    -0.02960863,\n",
       "    -0.03306224,\n",
       "    0.016201155,\n",
       "    -0.024043264,\n",
       "    -0.008414042,\n",
       "    0.0021928754,\n",
       "    0.049054418,\n",
       "    0.066036485,\n",
       "    -0.027166909,\n",
       "    0.061900955,\n",
       "    -0.079278976,\n",
       "    -0.020413676,\n",
       "    -0.02960863,\n",
       "    0.022745412,\n",
       "    0.02820079,\n",
       "    -0.02397727,\n",
       "    -0.0019522778,\n",
       "    -0.022415448,\n",
       "    -0.025275124,\n",
       "    -0.017740982,\n",
       "    0.017718984,\n",
       "    0.017422017,\n",
       "    0.005790841,\n",
       "    0.021832515,\n",
       "    0.08108277,\n",
       "    0.035283983,\n",
       "    0.021491554,\n",
       "    -0.0037643216,\n",
       "    0.005455379,\n",
       "    0.05912927,\n",
       "    0.017323028,\n",
       "    -0.046502706,\n",
       "    0.01898384,\n",
       "    0.044214968,\n",
       "    0.013726437,\n",
       "    0.0030466532,\n",
       "    -0.0014710826,\n",
       "    -0.021491554,\n",
       "    -0.021601541,\n",
       "    -0.0054718773,\n",
       "    0.025671078,\n",
       "    -0.021777522,\n",
       "    0.0071381875,\n",
       "    -0.000634834,\n",
       "    -0.014738322,\n",
       "    -0.01898384,\n",
       "    0.04861447,\n",
       "    -0.02432923,\n",
       "    0.031566408,\n",
       "    -0.005130916,\n",
       "    0.04234518,\n",
       "    -0.028838718,\n",
       "    -0.022833401,\n",
       "    -0.018026948,\n",
       "    0.0074296542,\n",
       "    -0.03304024,\n",
       "    0.036075894,\n",
       "    -0.0070886933,\n",
       "    -0.01827992,\n",
       "    -0.038671598,\n",
       "    0.004242767,\n",
       "    0.041795243,\n",
       "    -0.05138615,\n",
       "    0.026023038,\n",
       "    -0.00826556,\n",
       "    -0.04945037,\n",
       "    -0.019610768,\n",
       "    -0.046502706,\n",
       "    0.01124622,\n",
       "    0.043203082,\n",
       "    -0.0074241553,\n",
       "    -0.034778044,\n",
       "    0.05393786,\n",
       "    0.05631359,\n",
       "    -0.026682964,\n",
       "    0.03961749,\n",
       "    0.00024008205,\n",
       "    0.019456785,\n",
       "    -0.028002813,\n",
       "    -0.0082765585,\n",
       "    -0.024131253,\n",
       "    -0.017235039,\n",
       "    -0.07188782,\n",
       "    0.02494516,\n",
       "    0.04865846,\n",
       "    0.016905077,\n",
       "    -0.017510008,\n",
       "    -0.011191227,\n",
       "    -0.06740033,\n",
       "    -0.039397515,\n",
       "    -0.027870828,\n",
       "    0.020325687,\n",
       "    0.0024389725,\n",
       "    -0.009321439,\n",
       "    0.012813542,\n",
       "    -0.03066451,\n",
       "    0.024527209,\n",
       "    0.018554889,\n",
       "    -0.024219243,\n",
       "    -0.0010187591,\n",
       "    0.051694117,\n",
       "    -0.03794568,\n",
       "    -0.01476032,\n",
       "    0.030334547,\n",
       "    -0.011526688,\n",
       "    0.048438486,\n",
       "    0.018147934,\n",
       "    -0.054245826,\n",
       "    0.005812838,\n",
       "    -0.017444015,\n",
       "    0.008480035,\n",
       "    -0.03348019,\n",
       "    0.050638236,\n",
       "    0.01722404,\n",
       "    0.02679295,\n",
       "    -0.005735847,\n",
       "    0.011790658,\n",
       "    0.016817085,\n",
       "    -0.017532004,\n",
       "    -0.02934466,\n",
       "    -0.007583637,\n",
       "    0.008623019,\n",
       "    -0.047074642,\n",
       "    0.016641106,\n",
       "    0.0024499712,\n",
       "    -0.0073251664,\n",
       "    -0.030972475,\n",
       "    0.06423269,\n",
       "    0.030818492,\n",
       "    -0.0202047,\n",
       "    0.021777522,\n",
       "    0.016135164,\n",
       "    -0.016047174,\n",
       "    0.025803063,\n",
       "    -0.04821851,\n",
       "    -0.01010235,\n",
       "    0.07989491,\n",
       "    -0.008018088,\n",
       "    0.015398247,\n",
       "    0.0014071524,\n",
       "    -0.030290553,\n",
       "    -0.047162633,\n",
       "    -0.011779659,\n",
       "    0.016300146,\n",
       "    0.070787944,\n",
       "    -0.019621767,\n",
       "    0.001256607,\n",
       "    0.041333295,\n",
       "    0.01598118,\n",
       "    0.003453607,\n",
       "    -0.031302437,\n",
       "    0.0018697872,\n",
       "    -0.05560967,\n",
       "    -0.0034481075,\n",
       "    0.056049623,\n",
       "    0.017949957,\n",
       "    0.012945526,\n",
       "    -0.014023404,\n",
       "    0.023493325,\n",
       "    0.014122393,\n",
       "    0.06194495,\n",
       "    0.045182858,\n",
       "    -0.027804835,\n",
       "    -0.010949254,\n",
       "    -0.056621555,\n",
       "    0.0029119186,\n",
       "    -0.06458465,\n",
       "    0.021766523,\n",
       "    0.01449635,\n",
       "    -0.046062756,\n",
       "    0.0005619673,\n",
       "    -0.06044912,\n",
       "    -0.012934528,\n",
       "    -0.01722404,\n",
       "    0.032160338,\n",
       "    -0.008897987,\n",
       "    -0.025847059,\n",
       "    0.030532526,\n",
       "    -0.028068805,\n",
       "    -0.022877397,\n",
       "    -0.041069325,\n",
       "    -0.0075616394,\n",
       "    -0.0421912,\n",
       "    0.0063297795,\n",
       "    0.007094193,\n",
       "    0.006648743,\n",
       "    0.018125936,\n",
       "    -0.00206639,\n",
       "    -0.01951178,\n",
       "    0.011405702,\n",
       "    0.020534663,\n",
       "    0.0068412214,\n",
       "    -0.014430358,\n",
       "    0.01986374,\n",
       "    0.036251873,\n",
       "    -0.011878648,\n",
       "    0.052486025,\n",
       "    0.0037753202,\n",
       "    0.013363479,\n",
       "    0.030378543,\n",
       "    0.0050594243,\n",
       "    -0.008177569,\n",
       "    0.0130665125,\n",
       "    0.021931505,\n",
       "    0.011977637,\n",
       "    0.010652288,\n",
       "    -0.010674285,\n",
       "    0.03022456,\n",
       "    0.021139594,\n",
       "    0.0042290185,\n",
       "    -0.001730928,\n",
       "    -0.076243326,\n",
       "    -0.006791727,\n",
       "    -0.018917847,\n",
       "    0.00090258475,\n",
       "    -0.01107574,\n",
       "    -0.03209435,\n",
       "    -0.06273686,\n",
       "    0.017696986,\n",
       "    -0.015189271,\n",
       "    -0.08741805,\n",
       "    -0.007160185,\n",
       "    -0.019060832,\n",
       "    -0.007066696,\n",
       "    0.0008689011,\n",
       "    -0.014199384,\n",
       "    -0.037131775,\n",
       "    -0.013495464,\n",
       "    -0.019148821,\n",
       "    0.03145642,\n",
       "    -0.034404084,\n",
       "    0.0057193493,\n",
       "    0.022547433,\n",
       "    0.0034948522,\n",
       "    -0.024703188,\n",
       "    -0.02952064,\n",
       "    -0.016047174,\n",
       "    0.022085486,\n",
       "    -0.0029229173,\n",
       "    -0.012329597,\n",
       "    -0.013847424,\n",
       "    -0.043027103,\n",
       "    -0.0073251664,\n",
       "    0.04681067,\n",
       "    0.00019144696,\n",
       "    -0.03436009,\n",
       "    -0.018598882,\n",
       "    0.0142103825,\n",
       "    0.010069354,\n",
       "    -0.009282944,\n",
       "    0.06141701,\n",
       "    0.043950997,\n",
       "    0.0114386985,\n",
       "    0.001181678,\n",
       "    0.012835539,\n",
       "    0.030180564,\n",
       "    0.0034068623,\n",
       "    -0.014309372,\n",
       "    -0.0050841714,\n",
       "    -0.015607224,\n",
       "    0.010377319,\n",
       "    0.005166662,\n",
       "    0.012318598,\n",
       "    0.00738016,\n",
       "    -0.006296783,\n",
       "    0.004679967,\n",
       "    0.0066377446,\n",
       "    0.02714491,\n",
       "    0.051958088,\n",
       "    -0.0045369836,\n",
       "    -0.00057399715,\n",
       "    -0.014265376,\n",
       "    -0.027276896,\n",
       "    -0.022635425,\n",
       "    0.030356545,\n",
       "    -0.008430541,\n",
       "    0.006439767,\n",
       "    0.007215179,\n",
       "    0.014804315,\n",
       "    0.0077101225,\n",
       "    0.020105712,\n",
       "    0.040343408,\n",
       "    -0.005576365,\n",
       "    -0.017762978,\n",
       "    -0.0068577197,\n",
       "    0.0142103825,\n",
       "    -0.029718617,\n",
       "    -0.030070577,\n",
       "    0.052046075,\n",
       "    -0.0043637534,\n",
       "    -0.0048009534,\n",
       "    0.010652288,\n",
       "    0.00073004194,\n",
       "    -0.022635425,\n",
       "    -0.049010422,\n",
       "    0.013154503,\n",
       "    -0.0129015315,\n",
       "    0.0057413466,\n",
       "    0.017180044,\n",
       "    -0.033700164,\n",
       "    0.02170053,\n",
       "    -0.026770953,\n",
       "    -0.007391159,\n",
       "    -0.0026204519,\n",
       "    0.011339709,\n",
       "    -0.007011702,\n",
       "    0.012604565,\n",
       "    -0.015156275,\n",
       "    0.0067642303,\n",
       "    0.023911279,\n",
       "    0.00843604,\n",
       "    -0.0140564,\n",
       "    -0.01897284,\n",
       "    -0.00395405,\n",
       "    -0.013803429,\n",
       "    0.039507505,\n",
       "    0.013682443,\n",
       "    0.001564572,\n",
       "    -0.014001407,\n",
       "    -0.023053376,\n",
       "    -0.025363114,\n",
       "    0.0148593085,\n",
       "    0.02661697,\n",
       "    0.036845807,\n",
       "    0.0143643655,\n",
       "    -0.008210566,\n",
       "    -0.009381932,\n",
       "    0.017180044,\n",
       "    -0.032314323,\n",
       "    0.011988635,\n",
       "    0.009695397,\n",
       "    0.0125825675,\n",
       "    0.014155389,\n",
       "    -0.026045036,\n",
       "    0.018675875,\n",
       "    -0.024527209,\n",
       "    -0.035152,\n",
       "    -0.040651374,\n",
       "    0.00738016,\n",
       "    -0.016036175,\n",
       "    0.002917418,\n",
       "    0.011779659,\n",
       "    0.013374478,\n",
       "    -0.03392014,\n",
       "    -0.0210956,\n",
       "    -0.023449332,\n",
       "    0.029696621,\n",
       "    -0.022426447,\n",
       "    -0.04364303,\n",
       "    0.0023578566,\n",
       "    -0.00039045556,\n",
       "    0.0011500566,\n",
       "    0.0034206107,\n",
       "    -0.0044352454,\n",
       "    -0.05296997,\n",
       "    -0.019929731,\n",
       "    -0.010998748,\n",
       "    0.0045562317,\n",
       "    0.013484465,\n",
       "    -0.013385477,\n",
       "    0.0007101067,\n",
       "    0.020490669,\n",
       "    -0.0076386305,\n",
       "    -0.020281691,\n",
       "    -0.011004248,\n",
       "    0.0065277573,\n",
       "    -0.025011154,\n",
       "    -0.010234335,\n",
       "    0.00035195996,\n",
       "    -0.040805355,\n",
       "    0.011196726,\n",
       "    -0.0018670375,\n",
       "    -0.03277627,\n",
       "    -0.008826495,\n",
       "    0.026353002,\n",
       "    -0.031346433,\n",
       "    -0.0014284624,\n",
       "    -0.01977575,\n",
       "    0.024461215,\n",
       "    0.0025957045,\n",
       "    0.013561456,\n",
       "    0.028618744,\n",
       "    -0.0068632187,\n",
       "    -0.027408881,\n",
       "    0.0007705998,\n",
       "    -0.040915344,\n",
       "    0.009557912,\n",
       "    -0.004193273,\n",
       "    0.0026232013,\n",
       "    -0.025979044,\n",
       "    0.003802817,\n",
       "    0.028266784,\n",
       "    0.0120876245,\n",
       "    -0.024967158,\n",
       "    -0.011889647,\n",
       "    0.005290398,\n",
       "    0.009596407,\n",
       "    -0.0009568911,\n",
       "    0.0032088847,\n",
       "    -0.012483579,\n",
       "    -0.0058898297,\n",
       "    -0.019115824,\n",
       "    -0.0057798424,\n",
       "    -0.015354252,\n",
       "    0.019258808,\n",
       "    0.029234672,\n",
       "    -0.008227063,\n",
       "    0.030950477,\n",
       "    -0.01994073,\n",
       "    -0.03567994,\n",
       "    0.04527085,\n",
       "    -0.012494578,\n",
       "    0.010245334,\n",
       "    0.0146943275,\n",
       "    0.033106234,\n",
       "    0.022943389,\n",
       "    -0.008661514,\n",
       "    -0.0018670375,\n",
       "    0.029300665,\n",
       "    0.026462989,\n",
       "    0.0013720938,\n",
       "    -0.0060658096,\n",
       "    -0.0075726383,\n",
       "    0.053849872,\n",
       "    0.004674468,\n",
       "    -0.015211268,\n",
       "    0.015860194,\n",
       "    -0.0015604474,\n",
       "    -0.02846476,\n",
       "    0.009728393,\n",
       "    0.025539093,\n",
       "    -0.0009410804,\n",
       "    -0.007308668,\n",
       "    -0.07870704,\n",
       "    -0.009882376,\n",
       "    -0.01634414,\n",
       "    -0.049758337,\n",
       "    -0.005130916,\n",
       "    0.017356025,\n",
       "    0.029146682,\n",
       "    0.0059558223,\n",
       "    -0.041509274,\n",
       "    0.03499802,\n",
       "    0.015486238,\n",
       "    0.00016403601,\n",
       "    0.025165135,\n",
       "    -0.020391678,\n",
       "    0.036515843,\n",
       "    0.014980295,\n",
       "    0.009123461,\n",
       "    0.016806087,\n",
       "    0.029102689,\n",
       "    -0.008766002,\n",
       "    0.00024970595,\n",
       "    0.04430296,\n",
       "    -0.011548686,\n",
       "    0.012934528,\n",
       "    0.034118116,\n",
       "    -0.010366321,\n",
       "    -0.043137092,\n",
       "    0.05033027,\n",
       "    -0.00782011,\n",
       "    0.0019165318,\n",
       "    -0.021722527,\n",
       "    0.0048229513,\n",
       "    -0.017565,\n",
       "    -0.0060328133,\n",
       "    0.0075781373,\n",
       "    0.039683484,\n",
       "    -0.021458557,\n",
       "    0.004330757,\n",
       "    0.013825427,\n",
       "    -0.015959183,\n",
       "    0.0035525956,\n",
       "    0.014122393,\n",
       "    -0.014925301,\n",
       "    0.007627632,\n",
       "    -0.0166961,\n",
       "    0.037043784,\n",
       "    0.01572821,\n",
       "    -0.01765299,\n",
       "    -0.02443922,\n",
       "    0.0070391987,\n",
       "    0.02864074,\n",
       "    -0.020754637,\n",
       "    0.022239469,\n",
       "    0.033700164,\n",
       "    0.017982954,\n",
       "    -0.0029339162,\n",
       "    0.014749321,\n",
       "    -0.042213194,\n",
       "    -0.016190158,\n",
       "    -0.024527209,\n",
       "    -0.018774863,\n",
       "    -0.0006413645,\n",
       "    0.01089976,\n",
       "    -0.0298726,\n",
       "    -0.015365251,\n",
       "    0.005114418,\n",
       "    0.064320676,\n",
       "    0.01562922,\n",
       "    0.0009321439,\n",
       "    0.017773977,\n",
       "    -0.020226698,\n",
       "    -0.020776635,\n",
       "    -0.024219243,\n",
       "    0.023493325,\n",
       "    0.003813816,\n",
       "    -0.018037947,\n",
       "    -0.015937187,\n",
       "    -0.015079284,\n",
       "    0.0006482387,\n",
       "    -0.02952064,\n",
       "    0.03169839,\n",
       "    -0.0082875565,\n",
       "    -0.004558981,\n",
       "    0.008639516,\n",
       "    0.0038908073,\n",
       "    0.010195839,\n",
       "    -0.0088429935,\n",
       "    -0.020336686,\n",
       "    -0.007160185,\n",
       "    0.01132871,\n",
       "    -0.036735818,\n",
       "    0.031588405,\n",
       "    -0.041069325,\n",
       "    0.017850969,\n",
       "    0.022096485,\n",
       "    0.036471847,\n",
       "    0.025077146,\n",
       "    0.0046497206,\n",
       "    -0.010817269,\n",
       "    -0.010129847,\n",
       "    0.02382329,\n",
       "    0.0034398586,\n",
       "    0.006835722,\n",
       "    0.0228554,\n",
       "    -0.0054718773,\n",
       "    -0.033524185,\n",
       "    0.03084049,\n",
       "    -0.024065262,\n",
       "    0.008733006,\n",
       "    0.04527085,\n",
       "    0.000118838034,\n",
       "    0.04874645,\n",
       "    0.0059888186,\n",
       "    -0.022008495,\n",
       "    -0.01379243,\n",
       "    -0.004498488,\n",
       "    -0.013748435,\n",
       "    -0.034118116,\n",
       "    -0.010971251,\n",
       "    -0.0062912838,\n",
       "    -0.036053896,\n",
       "    -0.012021632,\n",
       "    0.018323915,\n",
       "    0.013077511,\n",
       "    -0.0029559135,\n",
       "    0.0070776944,\n",
       "    -0.002749687,\n",
       "    -0.0070886933,\n",
       "    0.009783386,\n",
       "    -0.014166388,\n",
       "    -0.04340106,\n",
       "    0.01951178,\n",
       "    0.02556109,\n",
       "    0.015651219,\n",
       "    -0.013253491,\n",
       "    0.0068907156,\n",
       "    0.007616633,\n",
       "    -0.032270327,\n",
       "    -0.008458037,\n",
       "    -0.015695214,\n",
       "    0.0050456757,\n",
       "    0.038011674,\n",
       "    -0.008529529,\n",
       "    0.015475239,\n",
       "    -0.006318781,\n",
       "    -0.026682964,\n",
       "    0.015057286,\n",
       "    -0.019170819,\n",
       "    -0.016025176,\n",
       "    0.014265376,\n",
       "    -0.02362531,\n",
       "    -0.0022368704,\n",
       "    0.029806608,\n",
       "    -0.016091168,\n",
       "    0.019478783,\n",
       "    -0.010943755,\n",
       "    -0.024879169,\n",
       "    0.015299259,\n",
       "    0.021590542,\n",
       "    0.025077146,\n",
       "    -0.0050979196,\n",
       "    0.015222267,\n",
       "    -0.009530416,\n",
       "    0.013396475,\n",
       "    -0.0069017145,\n",
       "    0.01713605,\n",
       "    -0.0010634415,\n",
       "    0.036427855,\n",
       "    0.019896736,\n",
       "    0.01643213,\n",
       "    -0.0035910914,\n",
       "    -0.01449635,\n",
       "    -0.010844766,\n",
       "    -0.026067033,\n",
       "    -0.019225812,\n",
       "    -0.040013447,\n",
       "    0.00949192,\n",
       "    0.06286885,\n",
       "    -0.013858423,\n",
       "    -0.049978312,\n",
       "    0.0024843423,\n",
       "    0.010217837,\n",
       "    -0.0105478,\n",
       "    -0.03609789,\n",
       "    -0.010377319,\n",
       "    -0.01731203,\n",
       "    -0.029300665,\n",
       "    -0.018345913,\n",
       "    -0.010030858,\n",
       "    -0.038605608,\n",
       "    -0.0070282,\n",
       "    0.027254898,\n",
       "    0.039947454,\n",
       "    -0.020171704,\n",
       "    -0.012560571,\n",
       "    -0.0027166908,\n",
       "    -0.047162633,\n",
       "    0.033722162,\n",
       "    -0.036075894,\n",
       "    0.0023221108,\n",
       "    0.017532004,\n",
       "    -0.0041877734,\n",
       "    0.014947299,\n",
       "    0.002601204,\n",
       "    -0.087022096,\n",
       "    0.031764384,\n",
       "    -0.0035360975,\n",
       "    -0.03990346,\n",
       "    -0.0069512087,\n",
       "    -0.015574227,\n",
       "    -0.00063964596,\n",
       "    ...],\n",
       "   'index': 0}],\n",
       " 'model': 'text-embedding-3-small',\n",
       " 'usage': {'prompt_tokens': 119, 'total_tokens': 119}}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "36dd1959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'Mangesh Sambare is an Indian Junior Data Scientist, AI Trainer, Technical Mentor, and Startup Professional with strong hands-on experience in Machine Learning, Deep Learning, Natural Language Processing, Data Analytics, and Generative AI. He is professionally associated with Affordable AI Technology, a data science and AI-focused organization that provides live project-based training, internships, and real-world industry exposure to students and freshers. He actively contributes to both technical development and training delivery within the organization. His primary technical expertise lies in Python and SQL for data analysis, preprocessing, automation, and backend logic. He works extensively with machine learning and deep learning frameworks such as TensorFlow and scikit-learn, and has experience building models using CNNs, LSTMs, RNNs, and traditional supervised and unsupervised learning algorithms. His workflow typically includes data collection, cleaning, feature engineering, model training, evaluation, optimization, and deployment. At Affordable AI Technology, Mangesh Sambare works as a Junior Data Scientist and Project Mentor, where he leads and supports multiple client-based and internal AI projects. His work includes NLP-based systems, time series forecasting models, AI chatbots, data dashboards, and automation pipelines. He plays a key role in mentoring interns and trainees by guiding them through Python programming, SQL querying, machine learning concepts, deployment practices, and real-time project execution. He is directly involved in delivering internship programs that emphasize hands-on learning with live datasets and industry-style problem statements. The organization operates with a strong focus on practical skills, real client exposure, and career-oriented training, and its branch operations have expanded to locations such as Buttibori. Before this role, he worked as a Data Analytics Intern at Softronix Software Services Pvt. Ltd., where he gained industry experience in data extraction, automation, and reporting. During this internship, he automated large-scale e-commerce data scraping using Selenium, BeautifulSoup, and ChromeDriver, significantly reducing manual data collection effort. He also designed a Flask-based data pipeline to handle automated data ingestion, preprocessing, and analysis. In addition, he developed Excel-based dashboards and reports to track business KPIs and product performance. Mangesh Sambare has completed several end-to-end machine learning and deep learning projects. He developed a fashion item classification system using Convolutional Neural Networks trained on the Fashion MNIST dataset, achieving approximately ninety-two percent accuracy through proper normalization, dropout regularization, and activation tuning. He built an LSTM-based sentiment analysis system for e-commerce reviews using thousands of labeled samples and achieved over ninety-two percent accuracy. This system was integrated into a Flask web application')\n",
      "(1, 'percent accuracy through proper normalization, dropout regularization, and activation tuning. He built an LSTM-based sentiment analysis system for e-commerce reviews using thousands of labeled samples and achieved over ninety-two percent accuracy. This system was integrated into a Flask web application for real-time sentiment prediction. He also completed a Flipkart product feedback analysis project involving the scraping of more than five thousand product reviews and ratings, followed by sentiment analysis and insight generation. Additionally, he developed automated image dataset acquisition tools using web scraping to collect high-quality image datasets from dynamically loaded web pages. His technical skill set spans Python, SQL, Pandas, NumPy, Machine Learning, Deep Learning, NLP, Computer Vision, Time Series Forecasting, Feature Engineering, Model Evaluation, Hyperparameter Tuning, ETL pipelines, Data Warehousing concepts, RESTful APIs, Flask-based backend systems, Power BI dashboards, Excel analytics, web scraping, automation, Git, GitHub, and Agile-style project workflows. He is comfortable working on both research-oriented prototypes and production-style applications. Apart from development work, Mangesh Sambare is deeply involved in teaching, mentoring, and content creation. He conducts structured training programs in Python, Data Science, Machine Learning, NLP, Deep Learning, Generative AI, Power BI, and Advanced Excel. His teaching approach emphasizes real-world examples, interview-oriented problem solving, and hands-on live projects. He regularly designs short-term courses such as Python Basics programs, Machine Learning bootcamps, and Data Science internship tracks that include training, project work, and career guidance. He runs a technical YouTube channel named “LearnCode_Mangesh” (also known as “LearnCode Infinity by Mangesh Sambare”), where he publishes educational videos on Python programming, data science fundamentals, machine learning algorithms, SQL roadmaps, interview preparation, coding logic, and real-time project demonstrations. His content targets beginners, students, interns, and early-career professionals aiming to enter the data science and AI field. Mangesh Sambare maintains an active GitHub profile where he hosts machine learning, NLP, generative AI, RAG-based systems, web scraping projects, and deployment-ready applications. His repositories often include complete pipelines, documentation, and practical implementations. On LinkedIn, he shares professional updates, technical milestones, training initiatives, and project-related insights, engaging with the broader data science and AI community. He holds a Master of Science degree in Electronics from RTMNU Campus, Maharashtra, completed between 2020 and 2022, and a Bachelor of Science degree in Physics, Mathematics, and Electronics from Kamla Nehru College, Nagpur, completed between 2016 and 2020. He has completed a Data Science Bootcamp from iNeuron and holds a Power BI certification from Satish Dhawale. Overall, Mangesh')\n",
      "(2, 'a Bachelor of Science degree in Physics, Mathematics, and Electronics from Kamla Nehru College, Nagpur, completed between 2016 and 2020. He has completed a Data Science Bootcamp from iNeuron and holds a Power BI certification from Satish Dhawale. Overall, Mangesh Sambare’s professional profile represents a combination of applied data science, AI engineering, technical mentoring, startup involvement, and educational content creation. His work focuses on building practical, scalable, and industry-relevant AI solutions while simultaneously training and guiding students and interns to become job-ready data professionals.')\n"
     ]
    }
   ],
   "source": [
    "for i in enumerate(chunks):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4d8c4206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.023845285,\n",
       " -0.018081943,\n",
       " 0.020523664,\n",
       " 0.028266784,\n",
       " 0.020083714,\n",
       " -0.026638968,\n",
       " 0.020886622,\n",
       " 0.04260915,\n",
       " 0.0036955795,\n",
       " -0.024835173,\n",
       " 0.033502188,\n",
       " 0.0027991815,\n",
       " -0.07492347,\n",
       " -0.016058173,\n",
       " 0.020171704,\n",
       " 0.089309834,\n",
       " -0.008645016,\n",
       " 0.007616633,\n",
       " -0.0061043054,\n",
       " 0.018037947,\n",
       " 0.033348203,\n",
       " 0.012846538,\n",
       " 0.064628646,\n",
       " -0.0100583555,\n",
       " 0.030862488,\n",
       " -0.0036680824,\n",
       " 0.032006357,\n",
       " 0.024527209,\n",
       " 0.014947299,\n",
       " 0.01994073,\n",
       " 0.02265742,\n",
       " -0.013253491,\n",
       " -0.013781431,\n",
       " 0.0015164524,\n",
       " 0.006621246,\n",
       " 0.016564114,\n",
       " -0.016564114,\n",
       " 0.008155572,\n",
       " -0.009788886,\n",
       " -0.009079467,\n",
       " -0.0057963403,\n",
       " -0.055037737,\n",
       " -0.0005819025,\n",
       " 0.08631817,\n",
       " -0.00054512545,\n",
       " -0.018862853,\n",
       " -0.04252116,\n",
       " -0.02479118,\n",
       " 0.020688646,\n",
       " 0.03875959,\n",
       " -0.011218723,\n",
       " -0.0289927,\n",
       " 0.016971068,\n",
       " 0.015585226,\n",
       " -0.022426447,\n",
       " 0.009629404,\n",
       " 0.02152455,\n",
       " 0.0058898297,\n",
       " -0.008331552,\n",
       " -0.03306224,\n",
       " 0.017861968,\n",
       " -0.0108007705,\n",
       " 0.0014435857,\n",
       " 0.037857693,\n",
       " 0.019753752,\n",
       " 0.04584278,\n",
       " -0.029850602,\n",
       " 0.015475239,\n",
       " 0.0022643672,\n",
       " -0.0137154395,\n",
       " 0.030708505,\n",
       " 0.049362384,\n",
       " -0.028420765,\n",
       " 0.013341482,\n",
       " -0.002793682,\n",
       " -0.0138804205,\n",
       " 0.021073602,\n",
       " -0.0048366995,\n",
       " 0.017773977,\n",
       " -0.025847059,\n",
       " 0.0057963403,\n",
       " 0.02679295,\n",
       " 0.04357704,\n",
       " -0.023713302,\n",
       " -0.050286278,\n",
       " 0.030598518,\n",
       " 0.006263787,\n",
       " -0.0029339162,\n",
       " -0.0694241,\n",
       " 0.012329597,\n",
       " -0.01994073,\n",
       " -0.06955609,\n",
       " -0.047118638,\n",
       " 0.0064452663,\n",
       " 0.031830378,\n",
       " 0.0058183377,\n",
       " 0.073471636,\n",
       " -0.04267514,\n",
       " 0.037549727,\n",
       " 0.030202562,\n",
       " -0.048306502,\n",
       " 0.027760841,\n",
       " 0.017576,\n",
       " 0.01694907,\n",
       " 0.051166177,\n",
       " -0.0042510163,\n",
       " 0.010756776,\n",
       " -0.05763344,\n",
       " 0.027056921,\n",
       " 0.00799059,\n",
       " -0.0711839,\n",
       " 0.0016333141,\n",
       " 0.026067033,\n",
       " 0.008738506,\n",
       " -0.042565156,\n",
       " -0.034822036,\n",
       " 0.028684735,\n",
       " -0.024967158,\n",
       " -0.04821851,\n",
       " 0.0070007034,\n",
       " 0.0070007034,\n",
       " 0.05684153,\n",
       " 0.005067673,\n",
       " -0.056049623,\n",
       " -0.0030961477,\n",
       " -0.004894443,\n",
       " 0.013275489,\n",
       " -0.026682964,\n",
       " 0.022030493,\n",
       " -0.016454127,\n",
       " -0.018213928,\n",
       " -0.047822557,\n",
       " 0.06159299,\n",
       " -0.03260029,\n",
       " 0.022184474,\n",
       " -0.038253646,\n",
       " -0.040497392,\n",
       " -0.024901167,\n",
       " -0.03486603,\n",
       " -0.013011519,\n",
       " -0.012846538,\n",
       " 0.0281128,\n",
       " 0.007979591,\n",
       " -0.016828084,\n",
       " -0.035657942,\n",
       " -0.00896398,\n",
       " 0.025055148,\n",
       " 0.021381566,\n",
       " 0.022987384,\n",
       " -0.015959183,\n",
       " -0.020369682,\n",
       " 0.037571725,\n",
       " -0.008254561,\n",
       " -0.010399316,\n",
       " 0.026023038,\n",
       " 0.009046471,\n",
       " 0.019819744,\n",
       " -0.00022014682,\n",
       " -0.021073602,\n",
       " -0.025319118,\n",
       " 0.012329597,\n",
       " 0.01915982,\n",
       " -0.033150226,\n",
       " 0.024615198,\n",
       " 0.023295349,\n",
       " -0.0042620148,\n",
       " -0.032314323,\n",
       " -0.0068412214,\n",
       " -0.039155543,\n",
       " -0.048790447,\n",
       " -0.03504201,\n",
       " -0.020842629,\n",
       " 0.007655129,\n",
       " -0.043467052,\n",
       " 0.039595492,\n",
       " 0.05323394,\n",
       " 0.006131802,\n",
       " -0.0020608904,\n",
       " -0.04865846,\n",
       " -0.07677126,\n",
       " -0.037659712,\n",
       " 0.007985091,\n",
       " -0.004058538,\n",
       " 0.026858943,\n",
       " -0.028420765,\n",
       " 0.022591429,\n",
       " 0.03724176,\n",
       " 0.028156795,\n",
       " 0.006472763,\n",
       " 0.0202157,\n",
       " 0.019929731,\n",
       " 0.040453397,\n",
       " -0.027276896,\n",
       " 0.03110446,\n",
       " -0.002170878,\n",
       " -0.050814215,\n",
       " 0.01414439,\n",
       " -0.02793682,\n",
       " -0.04293911,\n",
       " -0.04456693,\n",
       " 0.015596225,\n",
       " -0.020094713,\n",
       " 0.043357067,\n",
       " 0.037747703,\n",
       " 0.012549572,\n",
       " -0.017971955,\n",
       " 0.055653665,\n",
       " -0.029388655,\n",
       " -0.018763864,\n",
       " -0.023999268,\n",
       " 0.038341638,\n",
       " 0.014738322,\n",
       " 0.054861758,\n",
       " 0.01994073,\n",
       " -0.056621555,\n",
       " -0.014177387,\n",
       " -0.035393972,\n",
       " -0.009761389,\n",
       " 0.013913416,\n",
       " -0.0031208948,\n",
       " 0.0068907156,\n",
       " 0.045094866,\n",
       " -0.0063572763,\n",
       " -0.002601204,\n",
       " 0.0007582262,\n",
       " -0.009381932,\n",
       " 0.02205249,\n",
       " -0.017641991,\n",
       " 0.06251688,\n",
       " -0.049978312,\n",
       " 0.0012923529,\n",
       " 0.0061537996,\n",
       " 0.011031744,\n",
       " 0.0465467,\n",
       " -0.012538573,\n",
       " 0.022833401,\n",
       " 0.04067337,\n",
       " 0.021249581,\n",
       " -0.03145642,\n",
       " 0.014683329,\n",
       " -0.027606858,\n",
       " 0.032204334,\n",
       " 0.043005105,\n",
       " 0.009618405,\n",
       " 0.012439584,\n",
       " 0.006670741,\n",
       " -0.00087577535,\n",
       " -0.015706213,\n",
       " -0.034910027,\n",
       " 0.00782011,\n",
       " 0.0030823993,\n",
       " 0.011471694,\n",
       " 0.0094204275,\n",
       " -0.046502706,\n",
       " -0.042543158,\n",
       " -0.048394494,\n",
       " -0.02214048,\n",
       " 0.031676393,\n",
       " 0.02143656,\n",
       " 0.001642938,\n",
       " -0.0050374265,\n",
       " 0.002906419,\n",
       " -0.022008495,\n",
       " -0.022470443,\n",
       " -0.034844033,\n",
       " 0.025165135,\n",
       " -0.02188751,\n",
       " -0.020798633,\n",
       " -0.014441356,\n",
       " -0.02170053,\n",
       " -0.0068247234,\n",
       " -0.004457243,\n",
       " -0.0074021574,\n",
       " 0.02144756,\n",
       " -0.0071766833,\n",
       " 0.011548686,\n",
       " 0.0017446764,\n",
       " 0.024879169,\n",
       " -0.013165502,\n",
       " 0.00030504342,\n",
       " -0.008744005,\n",
       " 0.032446306,\n",
       " 0.009865877,\n",
       " 0.03277627,\n",
       " -0.015882192,\n",
       " 0.017740982,\n",
       " 0.024725186,\n",
       " 0.028486758,\n",
       " -0.021425562,\n",
       " -0.07008402,\n",
       " 0.029564636,\n",
       " 0.0016181908,\n",
       " -0.006835722,\n",
       " 0.008568025,\n",
       " 0.06361676,\n",
       " -0.06810425,\n",
       " 0.0033821152,\n",
       " 0.0059943176,\n",
       " 0.0005310333,\n",
       " 0.014276375,\n",
       " -0.026287008,\n",
       " -0.0049081915,\n",
       " 0.026462989,\n",
       " -0.008463536,\n",
       " -0.0024760931,\n",
       " -0.004369253,\n",
       " 0.021832515,\n",
       " 0.03488803,\n",
       " 0.04183924,\n",
       " -0.021370567,\n",
       " -0.0090079745,\n",
       " -0.011581682,\n",
       " -0.0138804205,\n",
       " -0.013836425,\n",
       " -0.041421287,\n",
       " -0.03306224,\n",
       " 0.0112847155,\n",
       " -0.043950997,\n",
       " 0.003558095,\n",
       " -0.01326449,\n",
       " 0.021755524,\n",
       " -0.032116346,\n",
       " 0.019610768,\n",
       " -0.054113843,\n",
       " -0.016267149,\n",
       " 0.019995725,\n",
       " -0.014826313,\n",
       " 0.011647674,\n",
       " -0.0008111577,\n",
       " 0.0038963065,\n",
       " 0.0154972365,\n",
       " 0.0035250988,\n",
       " -0.011015247,\n",
       " -0.008133574,\n",
       " 0.0051006693,\n",
       " 0.06300083,\n",
       " 0.004778956,\n",
       " 0.0058458345,\n",
       " 0.0028459262,\n",
       " -0.001370719,\n",
       " -0.043687027,\n",
       " -0.06493661,\n",
       " -0.041597266,\n",
       " -0.009304941,\n",
       " 0.041047327,\n",
       " -0.0015013291,\n",
       " -0.04848248,\n",
       " 0.0738236,\n",
       " 0.0030686508,\n",
       " -0.0066927383,\n",
       " -0.014595339,\n",
       " -0.022899393,\n",
       " 0.045754794,\n",
       " 0.008199567,\n",
       " 0.018521892,\n",
       " -0.03207235,\n",
       " -0.02960863,\n",
       " -0.03306224,\n",
       " 0.016201155,\n",
       " -0.024043264,\n",
       " -0.008414042,\n",
       " 0.0021928754,\n",
       " 0.049054418,\n",
       " 0.066036485,\n",
       " -0.027166909,\n",
       " 0.061900955,\n",
       " -0.079278976,\n",
       " -0.020413676,\n",
       " -0.02960863,\n",
       " 0.022745412,\n",
       " 0.02820079,\n",
       " -0.02397727,\n",
       " -0.0019522778,\n",
       " -0.022415448,\n",
       " -0.025275124,\n",
       " -0.017740982,\n",
       " 0.017718984,\n",
       " 0.017422017,\n",
       " 0.005790841,\n",
       " 0.021832515,\n",
       " 0.08108277,\n",
       " 0.035283983,\n",
       " 0.021491554,\n",
       " -0.0037643216,\n",
       " 0.005455379,\n",
       " 0.05912927,\n",
       " 0.017323028,\n",
       " -0.046502706,\n",
       " 0.01898384,\n",
       " 0.044214968,\n",
       " 0.013726437,\n",
       " 0.0030466532,\n",
       " -0.0014710826,\n",
       " -0.021491554,\n",
       " -0.021601541,\n",
       " -0.0054718773,\n",
       " 0.025671078,\n",
       " -0.021777522,\n",
       " 0.0071381875,\n",
       " -0.000634834,\n",
       " -0.014738322,\n",
       " -0.01898384,\n",
       " 0.04861447,\n",
       " -0.02432923,\n",
       " 0.031566408,\n",
       " -0.005130916,\n",
       " 0.04234518,\n",
       " -0.028838718,\n",
       " -0.022833401,\n",
       " -0.018026948,\n",
       " 0.0074296542,\n",
       " -0.03304024,\n",
       " 0.036075894,\n",
       " -0.0070886933,\n",
       " -0.01827992,\n",
       " -0.038671598,\n",
       " 0.004242767,\n",
       " 0.041795243,\n",
       " -0.05138615,\n",
       " 0.026023038,\n",
       " -0.00826556,\n",
       " -0.04945037,\n",
       " -0.019610768,\n",
       " -0.046502706,\n",
       " 0.01124622,\n",
       " 0.043203082,\n",
       " -0.0074241553,\n",
       " -0.034778044,\n",
       " 0.05393786,\n",
       " 0.05631359,\n",
       " -0.026682964,\n",
       " 0.03961749,\n",
       " 0.00024008205,\n",
       " 0.019456785,\n",
       " -0.028002813,\n",
       " -0.0082765585,\n",
       " -0.024131253,\n",
       " -0.017235039,\n",
       " -0.07188782,\n",
       " 0.02494516,\n",
       " 0.04865846,\n",
       " 0.016905077,\n",
       " -0.017510008,\n",
       " -0.011191227,\n",
       " -0.06740033,\n",
       " -0.039397515,\n",
       " -0.027870828,\n",
       " 0.020325687,\n",
       " 0.0024389725,\n",
       " -0.009321439,\n",
       " 0.012813542,\n",
       " -0.03066451,\n",
       " 0.024527209,\n",
       " 0.018554889,\n",
       " -0.024219243,\n",
       " -0.0010187591,\n",
       " 0.051694117,\n",
       " -0.03794568,\n",
       " -0.01476032,\n",
       " 0.030334547,\n",
       " -0.011526688,\n",
       " 0.048438486,\n",
       " 0.018147934,\n",
       " -0.054245826,\n",
       " 0.005812838,\n",
       " -0.017444015,\n",
       " 0.008480035,\n",
       " -0.03348019,\n",
       " 0.050638236,\n",
       " 0.01722404,\n",
       " 0.02679295,\n",
       " -0.005735847,\n",
       " 0.011790658,\n",
       " 0.016817085,\n",
       " -0.017532004,\n",
       " -0.02934466,\n",
       " -0.007583637,\n",
       " 0.008623019,\n",
       " -0.047074642,\n",
       " 0.016641106,\n",
       " 0.0024499712,\n",
       " -0.0073251664,\n",
       " -0.030972475,\n",
       " 0.06423269,\n",
       " 0.030818492,\n",
       " -0.0202047,\n",
       " 0.021777522,\n",
       " 0.016135164,\n",
       " -0.016047174,\n",
       " 0.025803063,\n",
       " -0.04821851,\n",
       " -0.01010235,\n",
       " 0.07989491,\n",
       " -0.008018088,\n",
       " 0.015398247,\n",
       " 0.0014071524,\n",
       " -0.030290553,\n",
       " -0.047162633,\n",
       " -0.011779659,\n",
       " 0.016300146,\n",
       " 0.070787944,\n",
       " -0.019621767,\n",
       " 0.001256607,\n",
       " 0.041333295,\n",
       " 0.01598118,\n",
       " 0.003453607,\n",
       " -0.031302437,\n",
       " 0.0018697872,\n",
       " -0.05560967,\n",
       " -0.0034481075,\n",
       " 0.056049623,\n",
       " 0.017949957,\n",
       " 0.012945526,\n",
       " -0.014023404,\n",
       " 0.023493325,\n",
       " 0.014122393,\n",
       " 0.06194495,\n",
       " 0.045182858,\n",
       " -0.027804835,\n",
       " -0.010949254,\n",
       " -0.056621555,\n",
       " 0.0029119186,\n",
       " -0.06458465,\n",
       " 0.021766523,\n",
       " 0.01449635,\n",
       " -0.046062756,\n",
       " 0.0005619673,\n",
       " -0.06044912,\n",
       " -0.012934528,\n",
       " -0.01722404,\n",
       " 0.032160338,\n",
       " -0.008897987,\n",
       " -0.025847059,\n",
       " 0.030532526,\n",
       " -0.028068805,\n",
       " -0.022877397,\n",
       " -0.041069325,\n",
       " -0.0075616394,\n",
       " -0.0421912,\n",
       " 0.0063297795,\n",
       " 0.007094193,\n",
       " 0.006648743,\n",
       " 0.018125936,\n",
       " -0.00206639,\n",
       " -0.01951178,\n",
       " 0.011405702,\n",
       " 0.020534663,\n",
       " 0.0068412214,\n",
       " -0.014430358,\n",
       " 0.01986374,\n",
       " 0.036251873,\n",
       " -0.011878648,\n",
       " 0.052486025,\n",
       " 0.0037753202,\n",
       " 0.013363479,\n",
       " 0.030378543,\n",
       " 0.0050594243,\n",
       " -0.008177569,\n",
       " 0.0130665125,\n",
       " 0.021931505,\n",
       " 0.011977637,\n",
       " 0.010652288,\n",
       " -0.010674285,\n",
       " 0.03022456,\n",
       " 0.021139594,\n",
       " 0.0042290185,\n",
       " -0.001730928,\n",
       " -0.076243326,\n",
       " -0.006791727,\n",
       " -0.018917847,\n",
       " 0.00090258475,\n",
       " -0.01107574,\n",
       " -0.03209435,\n",
       " -0.06273686,\n",
       " 0.017696986,\n",
       " -0.015189271,\n",
       " -0.08741805,\n",
       " -0.007160185,\n",
       " -0.019060832,\n",
       " -0.007066696,\n",
       " 0.0008689011,\n",
       " -0.014199384,\n",
       " -0.037131775,\n",
       " -0.013495464,\n",
       " -0.019148821,\n",
       " 0.03145642,\n",
       " -0.034404084,\n",
       " 0.0057193493,\n",
       " 0.022547433,\n",
       " 0.0034948522,\n",
       " -0.024703188,\n",
       " -0.02952064,\n",
       " -0.016047174,\n",
       " 0.022085486,\n",
       " -0.0029229173,\n",
       " -0.012329597,\n",
       " -0.013847424,\n",
       " -0.043027103,\n",
       " -0.0073251664,\n",
       " 0.04681067,\n",
       " 0.00019144696,\n",
       " -0.03436009,\n",
       " -0.018598882,\n",
       " 0.0142103825,\n",
       " 0.010069354,\n",
       " -0.009282944,\n",
       " 0.06141701,\n",
       " 0.043950997,\n",
       " 0.0114386985,\n",
       " 0.001181678,\n",
       " 0.012835539,\n",
       " 0.030180564,\n",
       " 0.0034068623,\n",
       " -0.014309372,\n",
       " -0.0050841714,\n",
       " -0.015607224,\n",
       " 0.010377319,\n",
       " 0.005166662,\n",
       " 0.012318598,\n",
       " 0.00738016,\n",
       " -0.006296783,\n",
       " 0.004679967,\n",
       " 0.0066377446,\n",
       " 0.02714491,\n",
       " 0.051958088,\n",
       " -0.0045369836,\n",
       " -0.00057399715,\n",
       " -0.014265376,\n",
       " -0.027276896,\n",
       " -0.022635425,\n",
       " 0.030356545,\n",
       " -0.008430541,\n",
       " 0.006439767,\n",
       " 0.007215179,\n",
       " 0.014804315,\n",
       " 0.0077101225,\n",
       " 0.020105712,\n",
       " 0.040343408,\n",
       " -0.005576365,\n",
       " -0.017762978,\n",
       " -0.0068577197,\n",
       " 0.0142103825,\n",
       " -0.029718617,\n",
       " -0.030070577,\n",
       " 0.052046075,\n",
       " -0.0043637534,\n",
       " -0.0048009534,\n",
       " 0.010652288,\n",
       " 0.00073004194,\n",
       " -0.022635425,\n",
       " -0.049010422,\n",
       " 0.013154503,\n",
       " -0.0129015315,\n",
       " 0.0057413466,\n",
       " 0.017180044,\n",
       " -0.033700164,\n",
       " 0.02170053,\n",
       " -0.026770953,\n",
       " -0.007391159,\n",
       " -0.0026204519,\n",
       " 0.011339709,\n",
       " -0.007011702,\n",
       " 0.012604565,\n",
       " -0.015156275,\n",
       " 0.0067642303,\n",
       " 0.023911279,\n",
       " 0.00843604,\n",
       " -0.0140564,\n",
       " -0.01897284,\n",
       " -0.00395405,\n",
       " -0.013803429,\n",
       " 0.039507505,\n",
       " 0.013682443,\n",
       " 0.001564572,\n",
       " -0.014001407,\n",
       " -0.023053376,\n",
       " -0.025363114,\n",
       " 0.0148593085,\n",
       " 0.02661697,\n",
       " 0.036845807,\n",
       " 0.0143643655,\n",
       " -0.008210566,\n",
       " -0.009381932,\n",
       " 0.017180044,\n",
       " -0.032314323,\n",
       " 0.011988635,\n",
       " 0.009695397,\n",
       " 0.0125825675,\n",
       " 0.014155389,\n",
       " -0.026045036,\n",
       " 0.018675875,\n",
       " -0.024527209,\n",
       " -0.035152,\n",
       " -0.040651374,\n",
       " 0.00738016,\n",
       " -0.016036175,\n",
       " 0.002917418,\n",
       " 0.011779659,\n",
       " 0.013374478,\n",
       " -0.03392014,\n",
       " -0.0210956,\n",
       " -0.023449332,\n",
       " 0.029696621,\n",
       " -0.022426447,\n",
       " -0.04364303,\n",
       " 0.0023578566,\n",
       " -0.00039045556,\n",
       " 0.0011500566,\n",
       " 0.0034206107,\n",
       " -0.0044352454,\n",
       " -0.05296997,\n",
       " -0.019929731,\n",
       " -0.010998748,\n",
       " 0.0045562317,\n",
       " 0.013484465,\n",
       " -0.013385477,\n",
       " 0.0007101067,\n",
       " 0.020490669,\n",
       " -0.0076386305,\n",
       " -0.020281691,\n",
       " -0.011004248,\n",
       " 0.0065277573,\n",
       " -0.025011154,\n",
       " -0.010234335,\n",
       " 0.00035195996,\n",
       " -0.040805355,\n",
       " 0.011196726,\n",
       " -0.0018670375,\n",
       " -0.03277627,\n",
       " -0.008826495,\n",
       " 0.026353002,\n",
       " -0.031346433,\n",
       " -0.0014284624,\n",
       " -0.01977575,\n",
       " 0.024461215,\n",
       " 0.0025957045,\n",
       " 0.013561456,\n",
       " 0.028618744,\n",
       " -0.0068632187,\n",
       " -0.027408881,\n",
       " 0.0007705998,\n",
       " -0.040915344,\n",
       " 0.009557912,\n",
       " -0.004193273,\n",
       " 0.0026232013,\n",
       " -0.025979044,\n",
       " 0.003802817,\n",
       " 0.028266784,\n",
       " 0.0120876245,\n",
       " -0.024967158,\n",
       " -0.011889647,\n",
       " 0.005290398,\n",
       " 0.009596407,\n",
       " -0.0009568911,\n",
       " 0.0032088847,\n",
       " -0.012483579,\n",
       " -0.0058898297,\n",
       " -0.019115824,\n",
       " -0.0057798424,\n",
       " -0.015354252,\n",
       " 0.019258808,\n",
       " 0.029234672,\n",
       " -0.008227063,\n",
       " 0.030950477,\n",
       " -0.01994073,\n",
       " -0.03567994,\n",
       " 0.04527085,\n",
       " -0.012494578,\n",
       " 0.010245334,\n",
       " 0.0146943275,\n",
       " 0.033106234,\n",
       " 0.022943389,\n",
       " -0.008661514,\n",
       " -0.0018670375,\n",
       " 0.029300665,\n",
       " 0.026462989,\n",
       " 0.0013720938,\n",
       " -0.0060658096,\n",
       " -0.0075726383,\n",
       " 0.053849872,\n",
       " 0.004674468,\n",
       " -0.015211268,\n",
       " 0.015860194,\n",
       " -0.0015604474,\n",
       " -0.02846476,\n",
       " 0.009728393,\n",
       " 0.025539093,\n",
       " -0.0009410804,\n",
       " -0.007308668,\n",
       " -0.07870704,\n",
       " -0.009882376,\n",
       " -0.01634414,\n",
       " -0.049758337,\n",
       " -0.005130916,\n",
       " 0.017356025,\n",
       " 0.029146682,\n",
       " 0.0059558223,\n",
       " -0.041509274,\n",
       " 0.03499802,\n",
       " 0.015486238,\n",
       " 0.00016403601,\n",
       " 0.025165135,\n",
       " -0.020391678,\n",
       " 0.036515843,\n",
       " 0.014980295,\n",
       " 0.009123461,\n",
       " 0.016806087,\n",
       " 0.029102689,\n",
       " -0.008766002,\n",
       " 0.00024970595,\n",
       " 0.04430296,\n",
       " -0.011548686,\n",
       " 0.012934528,\n",
       " 0.034118116,\n",
       " -0.010366321,\n",
       " -0.043137092,\n",
       " 0.05033027,\n",
       " -0.00782011,\n",
       " 0.0019165318,\n",
       " -0.021722527,\n",
       " 0.0048229513,\n",
       " -0.017565,\n",
       " -0.0060328133,\n",
       " 0.0075781373,\n",
       " 0.039683484,\n",
       " -0.021458557,\n",
       " 0.004330757,\n",
       " 0.013825427,\n",
       " -0.015959183,\n",
       " 0.0035525956,\n",
       " 0.014122393,\n",
       " -0.014925301,\n",
       " 0.007627632,\n",
       " -0.0166961,\n",
       " 0.037043784,\n",
       " 0.01572821,\n",
       " -0.01765299,\n",
       " -0.02443922,\n",
       " 0.0070391987,\n",
       " 0.02864074,\n",
       " -0.020754637,\n",
       " 0.022239469,\n",
       " 0.033700164,\n",
       " 0.017982954,\n",
       " -0.0029339162,\n",
       " 0.014749321,\n",
       " -0.042213194,\n",
       " -0.016190158,\n",
       " -0.024527209,\n",
       " -0.018774863,\n",
       " -0.0006413645,\n",
       " 0.01089976,\n",
       " -0.0298726,\n",
       " -0.015365251,\n",
       " 0.005114418,\n",
       " 0.064320676,\n",
       " 0.01562922,\n",
       " 0.0009321439,\n",
       " 0.017773977,\n",
       " -0.020226698,\n",
       " -0.020776635,\n",
       " -0.024219243,\n",
       " 0.023493325,\n",
       " 0.003813816,\n",
       " -0.018037947,\n",
       " -0.015937187,\n",
       " -0.015079284,\n",
       " 0.0006482387,\n",
       " -0.02952064,\n",
       " 0.03169839,\n",
       " -0.0082875565,\n",
       " -0.004558981,\n",
       " 0.008639516,\n",
       " 0.0038908073,\n",
       " 0.010195839,\n",
       " -0.0088429935,\n",
       " -0.020336686,\n",
       " -0.007160185,\n",
       " 0.01132871,\n",
       " -0.036735818,\n",
       " 0.031588405,\n",
       " -0.041069325,\n",
       " 0.017850969,\n",
       " 0.022096485,\n",
       " 0.036471847,\n",
       " 0.025077146,\n",
       " 0.0046497206,\n",
       " -0.010817269,\n",
       " -0.010129847,\n",
       " 0.02382329,\n",
       " 0.0034398586,\n",
       " 0.006835722,\n",
       " 0.0228554,\n",
       " -0.0054718773,\n",
       " -0.033524185,\n",
       " 0.03084049,\n",
       " -0.024065262,\n",
       " 0.008733006,\n",
       " 0.04527085,\n",
       " 0.000118838034,\n",
       " 0.04874645,\n",
       " 0.0059888186,\n",
       " -0.022008495,\n",
       " -0.01379243,\n",
       " -0.004498488,\n",
       " -0.013748435,\n",
       " -0.034118116,\n",
       " -0.010971251,\n",
       " -0.0062912838,\n",
       " -0.036053896,\n",
       " -0.012021632,\n",
       " 0.018323915,\n",
       " 0.013077511,\n",
       " -0.0029559135,\n",
       " 0.0070776944,\n",
       " -0.002749687,\n",
       " -0.0070886933,\n",
       " 0.009783386,\n",
       " -0.014166388,\n",
       " -0.04340106,\n",
       " 0.01951178,\n",
       " 0.02556109,\n",
       " 0.015651219,\n",
       " -0.013253491,\n",
       " 0.0068907156,\n",
       " 0.007616633,\n",
       " -0.032270327,\n",
       " -0.008458037,\n",
       " -0.015695214,\n",
       " 0.0050456757,\n",
       " 0.038011674,\n",
       " -0.008529529,\n",
       " 0.015475239,\n",
       " -0.006318781,\n",
       " -0.026682964,\n",
       " 0.015057286,\n",
       " -0.019170819,\n",
       " -0.016025176,\n",
       " 0.014265376,\n",
       " -0.02362531,\n",
       " -0.0022368704,\n",
       " 0.029806608,\n",
       " -0.016091168,\n",
       " 0.019478783,\n",
       " -0.010943755,\n",
       " -0.024879169,\n",
       " 0.015299259,\n",
       " 0.021590542,\n",
       " 0.025077146,\n",
       " -0.0050979196,\n",
       " 0.015222267,\n",
       " -0.009530416,\n",
       " 0.013396475,\n",
       " -0.0069017145,\n",
       " 0.01713605,\n",
       " -0.0010634415,\n",
       " 0.036427855,\n",
       " 0.019896736,\n",
       " 0.01643213,\n",
       " -0.0035910914,\n",
       " -0.01449635,\n",
       " -0.010844766,\n",
       " -0.026067033,\n",
       " -0.019225812,\n",
       " -0.040013447,\n",
       " 0.00949192,\n",
       " 0.06286885,\n",
       " -0.013858423,\n",
       " -0.049978312,\n",
       " 0.0024843423,\n",
       " 0.010217837,\n",
       " -0.0105478,\n",
       " -0.03609789,\n",
       " -0.010377319,\n",
       " -0.01731203,\n",
       " -0.029300665,\n",
       " -0.018345913,\n",
       " -0.010030858,\n",
       " -0.038605608,\n",
       " -0.0070282,\n",
       " 0.027254898,\n",
       " 0.039947454,\n",
       " -0.020171704,\n",
       " -0.012560571,\n",
       " -0.0027166908,\n",
       " -0.047162633,\n",
       " 0.033722162,\n",
       " -0.036075894,\n",
       " 0.0023221108,\n",
       " 0.017532004,\n",
       " -0.0041877734,\n",
       " 0.014947299,\n",
       " 0.002601204,\n",
       " -0.087022096,\n",
       " 0.031764384,\n",
       " -0.0035360975,\n",
       " -0.03990346,\n",
       " -0.0069512087,\n",
       " -0.015574227,\n",
       " -0.00063964596,\n",
       " ...]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c41116b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[\"data\"][0][\"embedding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "27daf09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9da84cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "826514bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_array = np.array(all_embedding,dtype= \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "29065041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0308245 , -0.02561136,  0.01309264, ...,  0.01644053,\n",
       "         0.03089624, -0.01211219],\n",
       "       [ 0.02976203, -0.02132408, -0.00225043, ..., -0.00446059,\n",
       "         0.01490579, -0.01374109],\n",
       "       [ 0.02384529, -0.01808194,  0.02052366, ..., -0.0048422 ,\n",
       "         0.02674896,  0.00363784]], shape=(3, 1536), dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "49dd16fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "base_index = faiss.IndexFlatL2(1536)   # L2 = Neuclidian distancce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2738be13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.13.2-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting numpy<3.0,>=1.25.0 (from faiss-cpu)\n",
      "  Using cached numpy-2.4.0-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting packaging (from faiss-cpu)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Using cached faiss_cpu-1.13.2-cp311-cp311-win_amd64.whl (18.9 MB)\n",
      "Using cached numpy-2.4.0-cp311-cp311-win_amd64.whl (12.6 MB)\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Installing collected packages: packaging, numpy, faiss-cpu\n",
      "\n",
      "  Attempting uninstall: packaging\n",
      "\n",
      "    Found existing installation: packaging 25.0\n",
      "\n",
      "    Uninstalling packaging-25.0:\n",
      "\n",
      "      Successfully uninstalled packaging-25.0\n",
      "\n",
      "  Attempting uninstall: numpy\n",
      "\n",
      "    Found existing installation: numpy 2.4.0\n",
      "\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "    Uninstalling numpy-2.4.0:\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "      Successfully uninstalled numpy-2.4.0\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "  Attempting uninstall: faiss-cpu\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "    Found existing installation: faiss-cpu 1.13.2\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "    Uninstalling faiss-cpu-1.13.2:\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "      Successfully uninstalled faiss-cpu-1.13.2\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   -------------------------- ------------- 2/3 [faiss-cpu]\n",
      "   -------------------------- ------------- 2/3 [faiss-cpu]\n",
      "   -------------------------- ------------- 2/3 [faiss-cpu]\n",
      "   -------------------------- ------------- 2/3 [faiss-cpu]\n",
      "   -------------------------- ------------- 2/3 [faiss-cpu]\n",
      "   ---------------------------------------- 3/3 [faiss-cpu]\n",
      "\n",
      "Successfully installed faiss-cpu-1.13.2 numpy-2.4.0 packaging-25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\SHREE\\anaconda3\\envs\\genai\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\SHREE\\anaconda3\\envs\\genai\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu --force-reinstall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a14dfb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_index.add(embedding_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "54474855",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(base_index,\"faiss_index.faiss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901e0aaa",
   "metadata": {},
   "source": [
    "### Ask a query to faiss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f9215d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_test  = \"tell me about the Mangesh Sambare college year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2e04e76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_text(text):\n",
    "    payload={\n",
    "        \"model\":MODEL_NAME,\n",
    "        \"input\":text\n",
    "    }\n",
    "    responce = requests.post(API_URI,headers=header,data = json.dumps(payload))\n",
    "    result  = responce.json()\n",
    "    embedding = result[\"data\"][0][\"embedding\"]\n",
    "    emb = np.array(embedding,dtype=\"float32\").reshape(1,-1)\n",
    "    return emb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1552d836",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_test_embeding = embedding_text(query_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cc930560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04013788, -0.03656097,  0.0157548 , ..., -0.00894911,\n",
       "         0.01395952, -0.00674084]], shape=(1, 1536), dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_test_embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1320d2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.91568  , 1.0437999, 1.0660416]], dtype=float32), array([[2, 0, 1]]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_index.search(query_test_embeding,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5b524fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a Bachelor of Science degree in Physics, Mathematics, and Electronics from Kamla Nehru College, Nagpur, completed between 2016 and 2020. He has completed a Data Science Bootcamp from iNeuron and holds a Power BI certification from Satish Dhawale. Overall, Mangesh Sambare’s professional profile represents a combination of applied data science, AI engineering, technical mentoring, startup involvement, and educational content creation. His work focuses on building practical, scalable, and industry-relevant AI solutions while simultaneously training and guiding students and interns to become job-ready data professionals.'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "223ed27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a Bachelor of Science degree in Physics, Mathematics, and Electronics from Kamla Nehru College, Nagpur, completed between 2016 and 2020. He has completed a Data Science Bootcamp from iNeuron and holds a Power BI certification from Satish Dhawale. Overall, Mangesh Sambare’s professional profile represents a combination of applied data science, AI engineering, technical mentoring, startup involvement, and educational content creation. His work focuses on building practical, scalable, and industry-relevant AI solutions while simultaneously training and guiding students and interns to become job-ready data professionals.'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028862e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
